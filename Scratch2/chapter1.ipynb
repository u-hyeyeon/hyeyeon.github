{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### CHAPTER 1. 신경망 복습\n",
    "1.2 신경망의 추론 <br>\n",
    ". 완전연결계층(fully connected layer) : 인접하는 층의 모든 뉴런과 연결되어 있다 <br>\n",
    ". h = xW + b ==>>>> x : 입력, h : 은닉층의 뉴런, W : 가중치, b : 편향"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "W1 = np.random.rand(2,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.93319577, 0.763515  , 0.80233501, 0.84859861],\n",
       "       [0.47677191, 0.42303724, 0.71727528, 0.62539816]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "b1 = np.random.rand(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.76284321, 0.20887844, 0.99357074, 0.31262929])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.randn(10,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.48354563,  0.53890784],\n",
       "       [-0.54513224,  1.12723469],\n",
       "       [ 0.04922107, -0.65369649],\n",
       "       [-1.69758154,  1.02197011],\n",
       "       [-0.43927595,  1.50756187],\n",
       "       [-0.60075312, -0.19884681],\n",
       "       [ 0.06643997,  0.26148626],\n",
       "       [ 0.17180995, -0.62619407],\n",
       "       [ 1.45549915,  0.75222232],\n",
       "       [-0.53314114,  0.66025154]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = np.matmul(x, W1) + b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.36465918, -0.69585282,  0.18981541, -0.6092735 ],\n",
       "       [ 0.79156195,  0.26952405,  1.36472964,  0.55500134],\n",
       "       [ 0.49711198, -0.0300785 ,  0.56418219, -0.05442236],\n",
       "       [-0.33408606, -0.65491911,  0.36457553, -0.48879782],\n",
       "       [ 1.07167591,  0.51123948,  1.72246113,  0.88268676],\n",
       "       [ 0.10741837, -0.33392519,  0.36893757, -0.3215274 ],\n",
       "       [ 0.94951401,  0.37022478,  1.23443548,  0.53254318],\n",
       "       [ 0.62462379,  0.0751545 ,  0.68226635,  0.06680636],\n",
       "       [ 2.47974733,  1.63839192,  2.70091913,  2.0182023 ],\n",
       "       [ 0.58010754,  0.08112817,  1.03939504,  0.27312656]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x) :\n",
    "    return 1 /  (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.40983218, 0.33273235, 0.54731188, 0.35222494],\n",
       "       [0.68816661, 0.56697606, 0.79652731, 0.63529516],\n",
       "       [0.6217804 , 0.49248094, 0.63741967, 0.48639777],\n",
       "       [0.41724675, 0.34188188, 0.59014759, 0.38017681],\n",
       "       [0.7449155 , 0.62509699, 0.84844557, 0.70737867],\n",
       "       [0.5268288 , 0.41728587, 0.59120223, 0.42030355],\n",
       "       [0.72101743, 0.59151329, 0.77459394, 0.63007607],\n",
       "       [0.65126943, 0.51877979, 0.66424434, 0.51669538],\n",
       "       [0.92270978, 0.83731601, 0.93708086, 0.882695  ],\n",
       "       [0.64109215, 0.52027093, 0.73873326, 0.56786031]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 선형함수를 비선형으로 바꾸기 위해 임의의 실수를 0에서 1 사이의 실수로 변환하고, a를 활성화(activation)라고 한다.\n",
    "a = sigmoid(h)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.18997694 -0.6368404 ]\n",
      " [ 0.77750232  0.32635143]\n",
      " [-0.322397   -0.52476212]\n",
      " [-0.8775561  -0.05718442]\n",
      " [-0.15380786  0.03307165]\n",
      " [ 0.72743413 -0.7718884 ]\n",
      " [-0.19903735 -0.65282213]\n",
      " [ 1.61164523  1.55990019]\n",
      " [ 1.14526457 -1.86634158]\n",
      " [-0.41059345  0.45754774]]\n",
      "[[ 1.29999112 -0.37205651  0.86716388 -0.35748381]\n",
      " [ 1.58616098  0.33545791 -0.1710531   0.02732165]]\n",
      "[-0.03814545 -0.48473461 -0.30132619 -2.03468955]\n",
      "[[-1.01813026 -0.62875005 -0.05781679]\n",
      " [ 0.11427557 -0.40581266 -0.07660894]\n",
      " [-0.44884516  1.21608889  0.0191739 ]\n",
      " [ 1.36005849  0.53489188  1.64635158]]\n",
      "[-0.47642573  0.0605255   1.64582394]\n"
     ]
    }
   ],
   "source": [
    "x = np.random.randn(10,2)    # 미니배치 10개, 2차원 데이터 2\n",
    "W1 = np.random.randn(2, 4)   # 2차원 데이터 2, 은닉층 뉴런 4\n",
    "b1 = np.random.randn(4)      # 뉴런의 수 4\n",
    "W2 = np.random.randn(4, 3)   # 뉴런의 수 4, 출력층의 개수 3\n",
    "b2 = np.random.randn(3)      # 출력층의 개수 3\n",
    "\n",
    "# h = xW + b ==> xW = h ==> 1x2(x) 2x4(W) 1x4(h)\n",
    "\n",
    "print(x)\n",
    "print(W1)\n",
    "print(b1)\n",
    "print(W2)\n",
    "print(b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 점수란 '확률'이 되기 전의 값으로 점수가 높을수록 그 뉴런에 해당하는 클래스의 확률도 높아진다.\n",
    "# 점수를 소프트맥스 함수에 입력하면 확률을 얻을 수 있다.\n",
    "\n",
    "# 여기에서 신경망 처리를 계층(Layer)으로 구현, 완전연결층에 의한 변환을 Affine 계층으로, 시그모이드 함수에 의한 변환을 Sigmoid 계층으로 구현\n",
    "# 순전파(forward propagation) : 입력층에서 출력층으로 향하는 전파\n",
    "# 역전파(backward propagation) : 신경망 학습에서 데이터(기울기)를 순전파와는 반대 방향으로 전파\n",
    "\n",
    "# - 계층구현의 규칙\n",
    "# 1) 모든 계층은 forward()와 backward() 메소드를 가진다.\n",
    "# 2) 모든 계층은 인스턴스 변수인 params와 grads를 가진다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.24660704 -1.85015289  1.58802297]\n",
      " [-1.30945971 -1.72496732  1.67744155]\n",
      " [-1.27720705 -1.80663322  1.60438522]\n",
      " [-1.38056006 -1.54079691  1.51551953]\n",
      " [-1.16441342 -1.97778105  1.49831985]\n",
      " [-1.4362684  -1.58914213  1.52445095]\n",
      " [-1.30148648 -1.75457943  1.64690466]\n",
      " [-1.41492768 -1.57073276  1.53195979]\n",
      " [-1.42349344 -1.63067996  1.5420135 ]\n",
      " [-1.35911111 -1.6887795   1.60903242]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Sigmoid:\n",
    "    def __init__(self):\n",
    "        self.params = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "class Affine:\n",
    "    def __init__(self, W, b):\n",
    "        self.params = [W, b]   # W : 가중치, b : 편향\n",
    "\n",
    "    def forward(self, x):\n",
    "        W, b = self.params\n",
    "        out = np.dot(x, W) + b\n",
    "        return out\n",
    "\n",
    "class TwoLayerNet:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        I, H, O = input_size, hidden_size, output_size\n",
    "\n",
    "        # 가중치와 편향 초기화\n",
    "        W1 = np.random.randn(I, H)     # I=2,H=4,O=3\n",
    "        b1 = np.random.randn(H)\n",
    "        W2 = np.random.randn(H, O)\n",
    "        b2 = np.random.randn(O)\n",
    "\n",
    "        # 계층 생성\n",
    "        #    layers[0] : Affine params(W1, b1)\n",
    "        #    layers[1] : Sigmoid params()\n",
    "        #    layers[2] : Affine params(W2, b2)\n",
    "        self.layers = [\n",
    "            Affine(W1, b1),\n",
    "            Sigmoid(),\n",
    "            Affine(W2, b2)\n",
    "        ]\n",
    "\n",
    "        # 모든 가중치를 리스트에 모은다.\n",
    "        #    self.params[0] : W1\n",
    "        #         params[1] : b1\n",
    "        #         params[2] : W2\n",
    "        #         params[3] : b2\n",
    "        self.params = []\n",
    "        for layer in self.layers:\n",
    "            self.params += layer.params\n",
    "\n",
    "    def predict(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer.forward(x)\n",
    "        return x\n",
    "\n",
    "x = np.random.randn(10, 2)     # 2개씩 10세트\n",
    "model = TwoLayerNet(2, 4, 3)   # 입력수, Hidden 수, 출력수\n",
    "s = model.predict(x)\n",
    "print(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.69072771e-01  1.61851743e+00]\n",
      " [-1.21547832e+00  3.33522394e-01]\n",
      " [ 5.96104948e-02  1.15093868e+00]\n",
      " [-2.40265462e-01 -1.18116791e+00]\n",
      " [ 7.63965319e-01  2.57456954e+00]\n",
      " [ 2.44840420e-01 -5.53214917e-01]\n",
      " [-5.49995535e-01  6.68396272e-01]\n",
      " [ 2.08007378e-03 -8.13745968e-01]\n",
      " [ 3.91435886e-01 -2.09657489e-01]\n",
      " [ 9.98717844e-02  9.58075720e-02]] \n",
      "\n",
      "[[-0.28594281  1.38327491 -0.21368318  0.20078174]\n",
      " [ 1.24718046 -1.53211791 -0.79122833 -1.36578588]] \n",
      "\n",
      "[ 2.10819276 -1.68177688  1.74115871 -3.27532134] \n",
      "\n",
      "[[-0.11059884 -0.24315787 -0.79270796]\n",
      " [-0.57589233  0.26637372 -0.63217611]\n",
      " [-0.36057885  0.52723246  0.35833487]\n",
      " [ 1.31383155 -0.32696723 -1.05760007]] \n",
      "\n",
      "[-0.910685   -1.94253666  2.15535233]\n"
     ]
    }
   ],
   "source": [
    "print(x, \"\\n\")\n",
    "# W1\n",
    "print(model.params[0], \"\\n\")\n",
    "# b1\n",
    "print(model.params[1], \"\\n\")\n",
    "# W2\n",
    "print(model.params[2], \"\\n\")\n",
    "# b2\n",
    "print(model.params[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실함수(lost function) : 신경망이 예측한 결과를 비교하여 예측이 얼마나 나쁜가를 산출한 단일값(스칼라)\n",
    "#  - 다중 클래스 분류(multi-class classification) 신경망 : 교차 엔트로피 오차(Cross Entropy Error)를 주로 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
